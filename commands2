PYTHONPATH="."  luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy explore_then_exploit --bandit-policy-params '{"explore_rounds": 1000}' --obs-batch-size 400 --batch-size 100 --num-episodes 10 



########################################

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy random --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup1.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy model --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup2.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=factorization_machine --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy model --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup2.1 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy epsilon_greedy  --bandit-policy-params '{"epsilon": 0.1}'  --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup3.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy lin_ucb --bandit-policy-params '{"alpha": 1e-4}' --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup8.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy adaptive --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup9.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy percentile_adaptive --bandit-policy-params '{"exploration_threshold": 0.7}' --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup10.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy softmax_explorer --bandit-policy-params '{"logit_multiplier": 5}' --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup11.0 &

PYTHONPATH="." nohup luigi --module recommendation.task.interaction InteractionTraining --filter-dish "Doces & Bolos" --local-scheduler --batch-size=512 --optimizer=radam --lr-scheduler=step --lr-scheduler-params='{"step_size": 5, "gamma": 0.801}' --learning-rate=0.001 --loss-function=crm  --use-normalize --use-buys-visits  --content-layers=[256,128,64]  --binary --predictor=logistic_regression --full-refit --item-embeddings --context-embeddings --use-numerical-content --user-embeddings --n-factors=50 --epochs 100 --bandit-policy explore_then_exploit --bandit-policy-params '{"explore_rounds": 1000}' --obs-batch-size 400 --batch-size 100 --num-episodes 10 > nohup12.0 &

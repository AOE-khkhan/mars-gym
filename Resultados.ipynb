{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AnÃ¡lise de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, \"/media/workspace/DeepFood/deep-reco-gym/tools/eval_viz\")\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import json\n",
    "from pandas.io.json import json_normalize\n",
    "from app import fetch_iteraction_results_path, load_all_iteraction_metrics\n",
    "from app import load_iteractions_params as load_iteractions_params2, PATH_EVAL_REINFORCEMENT\n",
    "from plot import plot_line_iteraction, plot_exploration_arm, get_colors\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import copy\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "\n",
    "#sys.path.insert(0, os.path.dirname(__file__))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_and_legend = {\n",
    "  \"____random_\":           [\"bandit_policy\", \"observation\"],\n",
    "  \"____fixed_\":            [\"bandit_policy\", \"observation\"],\n",
    "  \"____lin_ucb_\":          [\"bandit_policy\", \"bandit_policy_params.alpha\", \"full_refit\", \"val_split_type\"],\n",
    "  \"____model_\":            [\"bandit_policy\",\"full_refit\", \"val_split_type\"],\n",
    "  \"____custom_lin_ucb_\":   [\"bandit_policy\", \"bandit_policy_params.alpha\", \"full_refit\", \"val_split_type\"],\n",
    "  \"____epsilon_greedy_\":   [\"bandit_policy\",\"bandit_policy_params.epsilon\", \"full_refit\", \"val_split_type\"],\n",
    "  \"____softmax_\":          [\"bandit_policy\",\"bandit_policy_params.logit_multiplier\", \"full_refit\", \"val_split_type\"],\n",
    "  \"____lin_ts_\":           [\"bandit_policy\",\"bandit_policy_params.v_sq\", \"full_refit\", \"val_split_type\"],\n",
    "  \"____percentile_adapt_\":       [\"bandit_policy\",\"bandit_policy_params.exploration_threshold\", \"full_refit\", \"val_split_type\"],\n",
    "  \"____adaptive_\":         [\"bandit_policy\",\"bandit_policy_params.exploration_threshold\", \"bandit_policy_params.decay_rate\", \"full_refit\", \"val_split_type\"],  \n",
    "  \"____explore_then_exp_\": [\"bandit_policy\",\"bandit_policy_params.explore_rounds\", \"bandit_policy_params.decay_rate\", \"full_refit\", \"val_split_type\"],    \n",
    "}\n",
    "\n",
    "path = PATH_EVAL_REINFORCEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_paths_per_model(input_path):\n",
    "    models = []\n",
    "    \n",
    "    for model, legend in models_and_legend.items():\n",
    "    #print(model)\n",
    "    #print(legend)\n",
    "        for root, dirs, files in os.walk(input_path):\n",
    "            if '/results' in root and 'Interaction' in root:\n",
    "                for d in dirs:\n",
    "                    #print(os.path.join(root, d))\n",
    "                    if model in d:\n",
    "                        models.append(os.path.join(root, d))\n",
    "    return models\n",
    "\n",
    "def load_iteractions_params(iteractions):\n",
    "  if len(iteractions) == 0:\n",
    "    return pd.DataFrame()\n",
    "\n",
    "  dfs = []\n",
    "\n",
    "  for model in iteractions:\n",
    "\n",
    "    file_path = os.path.join(model, 'params.json')\n",
    "    data      = []\n",
    "\n",
    "    #try:\n",
    "    with open(file_path) as json_file:\n",
    "        d = json.load(json_file)\n",
    "        data.append(d)\n",
    "\n",
    "        df = pd.DataFrame.from_dict(json_normalize(data), orient='columns')\n",
    "      \n",
    "    #except:\n",
    "    #  df = pd.DataFrame()\n",
    "\n",
    "    df['iteraction'] = model\n",
    "    dfs.append(df)\n",
    "  \n",
    "  return pd.concat(dfs)\n",
    "\n",
    "\n",
    "def load_data_iteractions_metrics(path, sample_size = 10000):\n",
    "    random.seed(42)\n",
    "    file      = os.path.join(path,'sim-datalog.csv')\n",
    "\n",
    "    # Count the lines\n",
    "    num_lines = sum(1 for l in open(file)) - 1\n",
    "\n",
    "    # Sample size - in this case ~10%\n",
    "    size = np.min([sample_size, num_lines])#int(num_lines / 10)\n",
    "\n",
    "    # The row indices to skip - make sure 0 is not included to keep the header!\n",
    "    skip_idx  = sorted(random.sample(range(1, num_lines), num_lines - size))\n",
    "    idx       = list(set(list(range(num_lines))) - set(skip_idx))\n",
    "\n",
    "    df        = pd.read_csv(file, skiprows=skip_idx)\n",
    "    \n",
    "    df        = pd.read_csv(file)#.reset_index()\n",
    "    idx       = list(range(len(df)))\n",
    "\n",
    "    df['idx'] = sorted(idx)\n",
    "    df        = df.sort_values(\"idx\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_metrics_reward(bandits):\n",
    "    data    = []\n",
    "    for i, p in enumerate(bandits):\n",
    "        df_metrics = load_data_iteractions_metrics(p)\n",
    "        r_mean     = df_metrics.reward.mean()\n",
    "        r_reward   = df_metrics.reward.sum()\n",
    "        data.append((i, r_mean, r_reward))\n",
    "    df_metrics = pd.DataFrame(data, columns=['idx', 'r_mean', 'r_reward']).set_index('idx')    \n",
    "    return df_metrics\n",
    "\n",
    "def group_metrics(df):\n",
    "    df_g_metrics = df.groupby('bandit').agg({'r_mean': ['mean', 'std'], 'r_reward': ['mean', 'std', 'count'], 'model': 'first' })\n",
    "    df_g_metrics.columns = df_g_metrics.columns.map(lambda x: '|'.join([str(i) for i in x]))\n",
    "    return df_g_metrics    \n",
    "    \n",
    "result_paths = list_paths_per_model(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'data_frames_preparation_extra_params.filter_city'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/deep-reco-gym/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data_frames_preparation_extra_params.filter_city'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-5411c889010f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_iteractions_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_frames_preparation_extra_params.filter_city'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcity\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-reco-gym/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2978\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deep-reco-gym/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'data_frames_preparation_extra_params.filter_city'"
     ]
    }
   ],
   "source": [
    "city = \"Chicago, USA\"\n",
    "#city = \"Como, Italy\"\n",
    "\n",
    "df_params = load_iteractions_params(result_paths)\n",
    "df_params = df_params[df_params['data_frames_preparation_extra_params.filter_city'] == city]\n",
    "df_params.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_bandits          = df_params.groupby([\"bandit_policy\", \"observation\"])['iteraction'].apply(list).reset_index()\n",
    "list_bandits['name']  = list_bandits.bandit_policy.map(str) + ' ' + list_bandits.observation.map(str)\n",
    "list_bandits['model'] = list_bandits.iteraction.apply(lambda l: l[0])\n",
    "list_bandits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in list_bandits.iterrows():\n",
    "    df_metrics = get_metrics_reward(row['iteraction'])\n",
    "    df_metrics['bandit'] = row['name']\n",
    "    df_metrics['model']  = row['model']\n",
    "\n",
    "    df_g_metrics = group_metrics(df_metrics)\n",
    "    reward_metrics.append(df_g_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat(reward_metrics)\n",
    "df_all = df_all.reset_index().sort_values('bandit', ascending=False).set_index('bandit')\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all[['r_reward|mean', 'r_reward|std']].plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all.to_csv(\"output/tmp/stats.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "removed           = df_all.loc[['model ', 'fixed First Item']]['model|first'].values\n",
    "\n",
    "input_legend      = ['bandit_policy', 'observation']\n",
    "input_iteraction  = [p.split(\"/\")[-1] for p in df_all['model|first'] if p not in removed]\n",
    "sample_size       = 100000\n",
    "window_size       = 1000 \n",
    "\n",
    "st.set_option(\"client.displayEnabled\", False)\n",
    "\n",
    "metrics           = load_all_iteraction_metrics(input_iteraction, sample_size)\n",
    "params            = load_iteractions_params2(input_iteraction)\n",
    "\n",
    "df_metrics_reward = metrics.groupby(\"iteraction\").agg({'reward': ['mean', 'sum']}).reset_index().sort_values([('reward', 'sum')], ascending=False)\n",
    "\n",
    "df  = metrics.merge(params, on=['iteraction'], how='left')\\\n",
    "            .merge(metrics.groupby(\"iteraction\")\\\n",
    "                    .agg({'reward': 'mean'})\\\n",
    "                    .rename(columns={'reward': 'sum_reward'})\\\n",
    "                    .reset_index(), \n",
    "              on=['iteraction'], how='left')\\\n",
    "            .reset_index()\\\n",
    "            .sort_values(['sum_reward', 'idx'], ascending=[False, True])\n",
    "\n",
    "# GERAL\n",
    "for input_metrics in ['Cumulative Reward', 'Cumulative Window Mean Reward', 'Cumulative Mean Reward']:\n",
    "    #input_metrics = 'Cumulative Mean Reward'\n",
    "    fig = plot_line_iteraction(df, 'reward', \n",
    "                          title=input_metrics, \n",
    "                          legend=input_legend,\n",
    "                          yrange=[0, 0.4], \n",
    "                          line_dict=get_colors(input_iteraction),\n",
    "                          window=window_size,\n",
    "                          cum=(input_metrics == 'Cumulative Reward'), \n",
    "                          mean=(input_metrics == 'Cumulative Mean Reward'),\n",
    "                          roll=(input_metrics == 'Cumulative Window Mean Reward'))\n",
    "    fig.update_layout(xaxis_showgrid=False, yaxis_showgrid=False)\n",
    "    fig.show(renderer=\"svg\")\n",
    "\n",
    "    fig.write_image(\"output/tmp/iteraction_{}.eps\".format(input_metrics.replace(\" \", \"_\"))) #, width=1024, height=600, scale=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('deep-reco-gym': conda)",
   "language": "python",
   "name": "python36764bitdeeprecogymcondaefa3d91faad74829997320bb5734f593"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
